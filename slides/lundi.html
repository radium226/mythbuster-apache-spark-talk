<section>
  <img src="./images/résumé.png" />
  <aside class="notes">
Schéma qui résume tout de A à Z
  </aside>
</section>

<section>
  <h3>Optimisation</h3>
  <p>En deux mots&nbsp;:</p>
  <ul>
    <li>L'objectif est de <strong>réduire le temps d'execution</strong> sans changer le résultat&nbsp;;</li>
    <li>Au sein d'<em>Apache Spark</em>, le moteur d'execution s'appelle <em>Catalyst</em>&nbsp;;</li>
    <li>Deux familles d'optimiseur (<em>Rule Based Optimizer</em> et <em>Cost Based Optimizer</em>).</li>
  </ul>
  <aside class="notes">
Définition +

  </aside>
</section>

<section>
  <h3>Example d'optimisations dans <em>Apache Spark</em>&nbsp;:</h3>
  <ul>
    <li>Le <code>PushDownPredicate</code> pour filter le plus rapidement possible&nbsp;</li>
    <li>Le <code>ColumnPruning</code> pour ignorer les colonnes inutiles lors d'un <code>SELECT *</code>&nbsp;;</li>
    <li>Le <code>CombineFilters</code> qui assemble deux filtres avec un <code>AND</code>. </li>
  </ul>
</section>

<section>
  <img src="./images/catalystExample.png" style="background:none; border:none; box-shadow:none;"/>
</section>

<section>
  <h3>Comment appliquer ces transformations au travers du code&nbsp;?</h3>
  <pre class="bigger-code scala"><code data-trim data-noescape>
trait TreeNode[Type <: TreeNode[Type]] {
  self: Type =>

  def children: Seq[Type] = ???

  def transform(pf: PartialFunction[Type, Type]): Type = ???

}
  </code></pre>
</section>

<section>
  <h3>Ce qu'il faut retenir</h3>
  <ul>
    <li>le trait <code>TreeNode</code> nous aide à modéliser des structures en arbre immutables</li>
    <li>la methode <code>transform</code> permet de transformer l'arbre à l'aide de règles <em>ad-hoc</em></li>
    <li>le <em>Pattern Matching</em> et les <em>Partial Functions</em> permettent d'avoir une syntaxe simple et claire lors de la définition de ces règles</li>
  </ul>
</section>

<section>
  <h3>Implémentation du <code>CombineFilters</code></h3>
  <pre class="bigger-code scala"><code data-trim data-noescape>
object CombineFilters extends Rule[LogicalPlan] {
  def apply(plan: LogicalPlan): LogicalPlan = plan transform {
    case Filter(exp1, Filter(exp2, grandChild)) =>
          Filter(And(exp1, exp2), grandChild)
  }
}
  </code></pre>
</section>

<section>
  <h3>C'est bien, mais&hellip;</h3>
  <ul>
    <li>Un opérateur &harr; Une classe&nbsp;;</li>
    <li>Une classe &harr; Un appel à une fonction virtuelle&hellip;</li>
  </ul>
  <p class="fragment">On perd le pipelining&nbsp;!</p>
</section>

<section>
  <h3>Et si on l'écrivait à la main&hellip;</h3>
  <div>
    <div class="left-column">
      <pre class="bigger-code java"><code data-trim data-noescape>
while(rows.hasNext()) {
  Row currentRow = rows.next();
  if(currentRow
      .get("age") > 18)
    return currentRow
      .get("name");
}
      </code></pre>
    </div>
    <div class="right-column">
      <pre class="bigger-code scala"><code data-trim data-noescape>
Project("name",
  Filter(
    Expression("age",
      greaterThan(18)),
    CsvScan("people.csv")
  )
)
      </code></pre>
    </div>
  </div>
  <div style="clear: both;">
    <p>&hellip;C'est beaucoup plus performant&nbsp;!</p>
  </div>
  <aside class="notes">
Mouais... M O U A I S... TU TE FOUTERAIS PAS UN DE MA GUEULE ??
  </aside>
</section>

<section>
  <h3><em>Apache Spark</em> introduit le <code>WholeStageCodegen</code></h3>
  <p>Une classe &harr; <em>n</em> opérateurs</p>
</section>

<section>
  <aside class="notes">Schéma avec plusieurs opérateurs regroupés en 1 seul</aside>
</section>

<section>
  <h3>Comment avoir une seule classe qui contient les opérations de plusieurs classes sans les référencer ?</h3>
</section>

<section>
  <h3>La génération de code !!</h3>
  <aside class="notes">
    La génération de code nous permet d'avoir les performances d'un langage impératif avec la fléxibilité d'un langage orienté objet : mindblow !!
  </aside>
</section>

<section>
  <aside class="notes">
Montrer le trait <code>SupportCodeGenreation</code> et <code>doGenretaeCode</code>
  </aside>
</section>

<section>
  <aside class="notes">
Example de code généré <br />
Chacun des opérateurs génère un morceau de code <br />
  </aside>
</section>

<section>
  <aside class="notes">
    Example d'un debug de Spark pour avoir le plan d'execution (avec debug à true et tutti quanti)
  </aside>
</section>

<section>
  <aside class="notes">
Tout à l'heure, on l'a fait avec javac, mais Spark, il le fait avec Janino
  </aside>
</section>

<section>
  <aside class="notes">
Par contre : ça fait chier abec les UDF, ça ne marche qu'avec des oéprateurs à une seulle branche, voilà.
  </aside>
</section>

<section>
  <aside class="notes">
Benchmark + Si tu remplaces Spark 1.6 par Spark 2.2, normaement tu peux avoir jsuqu'à  10% de temps gagné sans changement d'API
  </aside>
</section>

<section>
  <aside class="notes">
Toutes les références (articles, liens vers Spark, etc.)
  </aside>
</section>

<section>
  <aside class="notes">
Merci
  </aside>
</section>
